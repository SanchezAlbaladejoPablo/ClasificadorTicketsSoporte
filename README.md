![Portada](docs/portada.png)

## ğŸš€ CaracterÃ­sticas

- **ClasificaciÃ³n automÃ¡tica** de tickets en tres categorÃ­as: Login, Billing y Technical
- **Backend API** con FastAPI para servir el modelo de ML
- **Frontend interactivo** con Streamlit para clasificar tickets y visualizar datos
- **Modelo de ML** entrenado con RegresiÃ³n LogÃ­stica y vectorizaciÃ³n TF-IDF
- **Dataset real** de tickets de soporte procesado y balanceado

## ğŸ“ Estructura del Proyecto

```
ClasificadorTicketsSoporteUpdated/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py          # AplicaciÃ³n frontend con Streamlit
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ main.py                   # API backend con FastAPI
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ all_tickets.csv           # Dataset completo descargado
â”‚   â””â”€â”€ sample_tickets.csv        # Muestra procesada y balanceada
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ticket_classifier.pkl     # Modelo entrenado y vectorizador
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ preprocess_data.py        # Script de preprocesamiento
â”‚   â””â”€â”€ training.py               # Script de entrenamiento del modelo
â”‚   â””â”€â”€ training.ipynb            # Notebook de Jupyter para documentar el entrenamiento
â”œâ”€â”€ requirements.txt              # Dependencias del proyecto
â””â”€â”€ README.md                     # Este archivo
```

## ğŸ› ï¸ InstalaciÃ³n

1. **Clonar o descargar el proyecto**
   ```bash
   # Si ya tienes el proyecto, navega a su directorio
   cd ClasificadorTicketsSoporteUpdated
   ```

2. **Instalar dependencias**
   ```bash
   pip install -r requirements.txt
   ```

3. **Descargar recursos de NLTK** (se hace automÃ¡ticamente al ejecutar los scripts)

## ğŸ“Š PreparaciÃ³n de Datos y Entrenamiento

### 1. Preprocesar los datos
```bash
cd notebooks
python preprocess_data.py
```

Este script:
- Carga el dataset de tickets de soporte (`all_tickets.csv`)
- Limpia y procesa el texto (eliminaciÃ³n de stopwords, lemmatizaciÃ³n)
- Categoriza automÃ¡ticamente los tickets en Login, Billing, Technical
- Balancea las categorÃ­as y guarda una muestra en `data/sample_tickets.csv`

### 2. Entrenar el modelo
```bash
cd notebooks
python training.py
```

Este script:
- Entrena un modelo de RegresiÃ³n LogÃ­stica con vectorizaciÃ³n TF-IDF
- EvalÃºa el modelo y muestra mÃ©tricas (accuracy, precision, recall, f1-score)
- Guarda el modelo entrenado en `models/ticket_classifier.pkl`

## ğŸš€ EjecuciÃ³n

### 1. Iniciar el backend (FastAPI)
En una terminal:
```bash
cd backend
python main.py
```

El backend estarÃ¡ disponible en: `http://localhost:8000`

**Endpoints disponibles:**
- `GET /`: Mensaje de bienvenida
- `POST /classify/`: Clasificar un ticket (envÃ­a JSON con campo "text")
- `GET /metrics/`: Obtener mÃ©tricas del modelo

### 2. Iniciar el frontend (Streamlit)
En **otra** terminal:
```bash
cd app
streamlit run streamlit_app.py
```

La aplicaciÃ³n estarÃ¡ disponible en: `http://localhost:8501`

## ğŸ“ˆ MÃ©tricas del Modelo

El modelo actual alcanza las siguientes mÃ©tricas en el conjunto de prueba:
- **Accuracy**: ~79%
- **Precision**: ~83%
- **Recall**: ~79%
- **F1-Score**: ~79%

## ğŸ¯ Uso de la AplicaciÃ³n

### Frontend (Streamlit)
1. Ingresa el texto del ticket en el Ã¡rea de texto
2. Haz clic en "Clasificar Ticket"
3. Observa la categorÃ­a predicha y la probabilidad
4. Revisa las mÃ©tricas del modelo en la barra lateral
5. Explora las visualizaciones del dataset

### API (FastAPI)
```bash
# Clasificar un ticket
curl -X POST "http://localhost:8000/classify/" \
     -H "Content-Type: application/json" \
     -d '{"text": "No puedo acceder a mi cuenta"}'

# Obtener mÃ©tricas
curl -X GET "http://localhost:8000/metrics/"
```

## ğŸ“‹ Dependencias Principales

- **pandas**: ManipulaciÃ³n de datos
- **scikit-learn**: Machine Learning
- **nltk**: Procesamiento de lenguaje natural
- **fastapi**: Framework web para la API
- **uvicorn**: Servidor ASGI para FastAPI
- **streamlit**: Framework para el frontend

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## ğŸ› SoluciÃ³n de Problemas

### Error: "Backend no disponible"
- AsegÃºrate de que FastAPI estÃ© ejecutÃ¡ndose en `http://localhost:8000`
- Verifica que no haya conflictos de puertos

### Error: "Dataset no encontrado"
- AsegÃºrate de que el archivo `all_tickets.csv` estÃ© en la carpeta `data/`
- Ejecuta `cd notebooks` y luego `python preprocess_data.py` para generar `sample_tickets.csv`

### Error: "Modelo no encontrado"
- Ejecuta `cd notebooks` y luego `python preprocess_data.py` para generar `sample_tickets.csv`
- Luego, ejecuta `cd notebooks` y `python training.py` para entrenar y guardar el modelo
- Verifica que el archivo `ticket_classifier.pkl` estÃ© en la carpeta `models/`
